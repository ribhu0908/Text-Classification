{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os,sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from 20_newspapers folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]   #x is the list where 1st element is no. of document and second element is text in document\n",
    "y=[]   # y is the category of document\n",
    "for category in os.listdir(\"20_newsgroups\"):\n",
    "    for document in os.listdir(\"20_newsgroups/\"+category):\n",
    "        with open(\"20_newsgroups/\"+category+'/'+document, \"r\") as f:\n",
    "            x.append((document,f.read()))\n",
    "            y.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of data Points:  19997 19997\n"
     ]
    }
   ],
   "source": [
    "print(\"The total number of data Points: \",len(x),len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classes/categories are:  {'rec.autos', 'comp.graphics', 'sci.crypt', 'talk.politics.mideast', 'talk.politics.misc', 'talk.politics.guns', 'comp.os.ms-windows.misc', 'alt.atheism', 'sci.space', 'rec.sport.hockey', 'comp.windows.x', 'rec.motorcycles', 'talk.religion.misc', 'soc.religion.christian', 'misc.forsale', 'comp.sys.ibm.pc.hardware', 'sci.electronics', 'rec.sport.baseball', 'sci.med', 'comp.sys.mac.hardware'}\n"
     ]
    }
   ],
   "source": [
    "#x stores the data\n",
    "#y stores the categories/class\n",
    "print(\"The classes/categories are: \",set(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14997 5000 14997 5000\n"
     ]
    }
   ],
   "source": [
    "#random splitting the data into train and test\n",
    "x_train,x_test,y_train,y_test= train_test_split(x,y)\n",
    "print( len(x_train), len(x_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> LIST OF STOPWORDS </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=[\"a\",\"about\",\"above\",\"after\",\"again\",\"against\",\"all\",\"am\",\"an\",\"and\",\"any\",\"are\",\"as\",\"at\",\"be\",\"because\",\"been\",\"before\",\"being\",\"below\",\"between\",\"both\",\"but\",\n",
    "\"by\",\"could\",\"did\",\"do\",\"does\",\"doing\",\"down\",\"during\",\"each\",\"few\",\"for\",\"from\",\"further\",\"had\",\"has\",\"have\",\"having\",\"he\",\"he'd\",\"he'll\",\"he's\",\"her\",\n",
    "\"here\",\"here's\",\"hers\",\"herself\",\"him\",\"himself\",\"his\",\"how\",\"how's\",\"i\",\"i'd\",\"i'll\",\"i'm\",\"i've\",\"if\",\"in\",\"into\",\"is\",\"it\",\"it's\",\"its\",\"itself\",\"let's\",\"me\",\n",
    "\"more\",\"most\",\"my\",\"myself\",\"nor\",\"of\",\"on\",\"once\",\"only\",\"or\",\"other\",\"ought\",\"our\",\"ours\",\"ourselves\",\"out\",\"over\",\"own\",\"same\",\"she\",\n",
    "\"she'd\",\"she'll\",\"she's\",\"should\",\"so\",\"some\",\"such\",\"than\",\"that\",\"that's\",\"the\",\"their\",\"theirs\",\"them\",\"themselves\",\"then\",\"there\",\"there's\",\n",
    "\"these\",\"they\",\"they'd\",\"they'll\",\"they're\",\"they've\",\"this\",\"those\",\"through\",\"to\",\"too\",\"under\",\"until\",\"up\",\"very\",\"was\",\"we\",\"we'd\",\n",
    "\"we'll\",\"we're\",\"we've\",\"were\",\"what\",\"what's\",\"when\",\"when's\",\"where\",\"where's\",\"which\",\"while\",\"who\",\"who's\",\"whom\",\"why\",\"why's\",\"with\",\n",
    "\"would\",\"you\",\"you'd\",\"you'll\",\"you're\",\"you've\",\"your\",\"yours\",\"yourself\",\"yourselves\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE THE VOCABOLARY FROM TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92772"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re,string\n",
    "import operator\n",
    "dic={}    #words with coreesonding frequency\n",
    "for i in range (len(x_train)):\n",
    "    word=x_train[i][1].lower()\n",
    "    stripped=re.split(r'\\W+',word)\n",
    "    for s in stripped:\n",
    "        if not (s.isalpha()) or s in stop_words or len(s)<=2:\n",
    "            continue\n",
    "        if s in dic:\n",
    "            dic[s]+=1\n",
    "        else:\n",
    "            dic[s]=1\n",
    "sorted_dic = sorted(dic.items(), key=operator.itemgetter(1),reverse=True) #list of words & freq in desc order\n",
    "len(sorted_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#No of words vs frequency graph\n",
    "features=sorted_dic\n",
    "ans1=[]\n",
    "ans2=[]\n",
    "for i in range (len(features)):\n",
    "    ans1.append(i)\n",
    "    ans2.append(features[i][1])\n",
    "plt.plot(ans1,ans2)\n",
    "plt.axis([0,8000,1,2000])\n",
    "plt.title(\"No of words vs frequency\")\n",
    "plt.xlabel(\"No of words\")\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.grid()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the top 2000 words: frequency and put into vocabulary-dictionary(Since, they matter)\n",
    "#vocabulary is implemented as dict due to O(1) search time\n",
    "vocabulary= {}\n",
    "for i in range(2000):\n",
    "    vocabulary[features[i][0]]= features[i][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataSet(x):\n",
    "    \n",
    "    columns= list(vocabulary.keys())\n",
    "    dataSet= np.zeros((len(x), len(columns))) #create a zero array\n",
    "    for i in range(len(x)): #go through each document\n",
    "        words=x[i][1].lower()\n",
    "        word=re.split(r'\\W+',words)\n",
    "        for j in word:\n",
    "            if j in vocabulary: #if present in the vocab, add in dataSet and increase frequency\n",
    "                 dataSet[i][columns.index(j)]+=1\n",
    "    return dataSet             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_data= createDataSet(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_data= createDataSet(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edu</th>\n",
       "      <th>cmu</th>\n",
       "      <th>com</th>\n",
       "      <th>news</th>\n",
       "      <th>not</th>\n",
       "      <th>srv</th>\n",
       "      <th>cantaloupe</th>\n",
       "      <th>net</th>\n",
       "      <th>message</th>\n",
       "      <th>subject</th>\n",
       "      <th>...</th>\n",
       "      <th>bedfellow</th>\n",
       "      <th>apc</th>\n",
       "      <th>brother</th>\n",
       "      <th>holocaust</th>\n",
       "      <th>operating</th>\n",
       "      <th>minor</th>\n",
       "      <th>davidians</th>\n",
       "      <th>hst</th>\n",
       "      <th>active</th>\n",
       "      <th>client</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14992</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14993</th>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14997 rows Ã— 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        edu  cmu  com  news  not  srv  cantaloupe  net  message  subject  ...  \\\n",
       "0       9.0  4.0  9.0   0.0  3.0  3.0         2.0  1.0      1.0      1.0  ...   \n",
       "1       5.0  3.0  8.0   1.0  2.0  2.0         1.0  1.0      1.0      1.0  ...   \n",
       "2      13.0  4.0  4.0   4.0  9.0  2.0         1.0  1.0      1.0      1.0  ...   \n",
       "3       7.0  1.0  0.0   3.0  1.0  1.0         1.0  0.0      1.0      1.0  ...   \n",
       "4       4.0  3.0  9.0   0.0  1.0  2.0         1.0  0.0      1.0      2.0  ...   \n",
       "...     ...  ...  ...   ...  ...  ...         ...  ...      ...      ...  ...   \n",
       "14992   8.0  4.0  1.0   3.0  0.0  1.0         1.0  1.0      1.0      1.0  ...   \n",
       "14993  12.0  2.0  0.0   1.0  0.0  1.0         1.0  0.0      1.0      1.0  ...   \n",
       "14994  14.0  1.0  0.0   2.0  1.0  1.0         1.0  3.0      1.0      1.0  ...   \n",
       "14995   3.0  1.0  0.0   1.0  0.0  1.0         1.0  7.0      1.0      1.0  ...   \n",
       "14996   9.0  1.0  1.0   2.0  1.0  1.0         1.0  1.0      1.0      1.0  ...   \n",
       "\n",
       "       bedfellow  apc  brother  holocaust  operating  minor  davidians  hst  \\\n",
       "0            0.0  0.0      0.0        0.0        0.0    0.0        0.0  0.0   \n",
       "1            0.0  0.0      0.0        0.0        0.0    0.0        0.0  0.0   \n",
       "2            0.0  0.0      0.0        0.0        0.0    0.0        0.0  0.0   \n",
       "3            0.0  0.0      0.0        0.0        0.0    0.0        0.0  0.0   \n",
       "4            0.0  0.0      0.0        0.0        0.0    0.0        0.0  0.0   \n",
       "...          ...  ...      ...        ...        ...    ...        ...  ...   \n",
       "14992        0.0  0.0      0.0        0.0        0.0    0.0        0.0  0.0   \n",
       "14993        0.0  0.0      0.0        0.0        0.0    0.0        0.0  0.0   \n",
       "14994        0.0  0.0      0.0        0.0        0.0    0.0        0.0  0.0   \n",
       "14995        0.0  0.0      0.0        0.0        0.0    0.0        0.0  0.0   \n",
       "14996        0.0  0.0      0.0        0.0        0.0    0.0        0.0  0.0   \n",
       "\n",
       "       active  client  \n",
       "0         0.0     0.0  \n",
       "1         0.0     1.0  \n",
       "2         0.0     0.0  \n",
       "3         0.0     0.0  \n",
       "4         0.0     0.0  \n",
       "...       ...     ...  \n",
       "14992     0.0     0.0  \n",
       "14993     0.0     0.0  \n",
       "14994     0.0     0.0  \n",
       "14995     0.0     0.0  \n",
       "14996     0.0     0.0  \n",
       "\n",
       "[14997 rows x 2000 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting a numPy 2D array into dataFrame(for easy visualisation)\n",
    "df_xtrain = pd.DataFrame(x_train_data, columns= vocabulary.keys())\n",
    "df_xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_data = np.array(y_train) \n",
    "y_test_data = np.array(y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['comp.sys.ibm.pc.hardware', 'rec.sport.baseball',\n",
       "       'comp.sys.mac.hardware', ..., 'alt.atheism', 'talk.religion.misc',\n",
       "       'rec.motorcycles'], dtype='<U24')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><u> x_train_data, x_test_data, y_train_data, y_test_data are the DataSets in the required format </u></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Sklearn Multinomial Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY OF SKLEARN NAIVEBAYES:  0.8666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "clf = MultinomialNB()\n",
    "clf.fit(x_train_data, y_train_data)\n",
    "y_pred = clf.predict(x_test_data)\n",
    "print(\"ACCURACY OF SKLEARN NAIVEBAYES: \",clf.score(x_test_data,y_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.79      0.82      0.81       257\n",
      "           comp.graphics       0.86      0.76      0.81       248\n",
      " comp.os.ms-windows.misc       0.85      0.84      0.85       251\n",
      "comp.sys.ibm.pc.hardware       0.74      0.82      0.78       218\n",
      "   comp.sys.mac.hardware       0.83      0.90      0.86       255\n",
      "          comp.windows.x       0.89      0.76      0.82       232\n",
      "            misc.forsale       0.78      0.94      0.85       245\n",
      "               rec.autos       0.88      0.91      0.89       232\n",
      "         rec.motorcycles       0.91      0.96      0.93       254\n",
      "      rec.sport.baseball       0.94      0.92      0.93       266\n",
      "        rec.sport.hockey       0.94      0.93      0.93       241\n",
      "               sci.crypt       0.98      0.95      0.96       256\n",
      "         sci.electronics       0.85      0.91      0.88       264\n",
      "                 sci.med       0.96      0.89      0.92       230\n",
      "               sci.space       0.95      0.91      0.93       257\n",
      "  soc.religion.christian       0.94      1.00      0.97       258\n",
      "      talk.politics.guns       0.82      0.92      0.87       268\n",
      "   talk.politics.mideast       0.95      0.88      0.92       248\n",
      "      talk.politics.misc       0.80      0.72      0.76       255\n",
      "      talk.religion.misc       0.70      0.60      0.65       265\n",
      "\n",
      "                accuracy                           0.87      5000\n",
      "               macro avg       0.87      0.87      0.87      5000\n",
      "            weighted avg       0.87      0.87      0.87      5000\n",
      "\n",
      "[[212   0   0   0   0   0   1   1   2   0   0   0   0   1   1   2   0   1\n",
      "    0  36]\n",
      " [  0 188  12  20   7   6   7   2   1   0   0   1   2   0   2   0   0   0\n",
      "    0   0]\n",
      " [  0   4 211  15   1  14   4   0   0   0   0   0   1   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   4   2 179  27   1   2   0   0   0   0   0   3   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   3   2  12 229   0   5   0   0   0   0   0   4   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0  12  19   8   4 177   4   0   2   0   1   0   2   2   1   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   3   2   0 231   3   2   0   0   0   3   0   0   0   1   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   9 210   4   0   1   0   7   0   0   0   0   0\n",
      "    0   1]\n",
      " [  0   0   0   0   0   1   5   4 243   0   0   0   0   1   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   3   3   2 244  12   0   0   0   2   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   4   2   0  11 223   0   0   0   0   0   0   0\n",
      "    1   0]\n",
      " [  0   2   1   0   0   1   1   0   0   0   0 243   6   1   0   0   1   0\n",
      "    0   0]\n",
      " [  0   0   0   4   6   0   3   6   1   0   0   0 239   2   2   0   0   1\n",
      "    0   0]\n",
      " [  0   2   0   1   1   0   7   0   5   0   0   0   6 205   1   0   0   1\n",
      "    0   1]\n",
      " [  1   4   0   0   0   0   2   3   0   4   0   0   7   1 233   0   0   0\n",
      "    2   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 258   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   1   2   0   0   3   0   0   0   0 246   0\n",
      "   11   5]\n",
      " [  0   0   0   0   0   0   5   3   2   0   0   0   0   0   0   0   7 219\n",
      "   11   1]\n",
      " [  0   0   0   0   0   0   3   0   0   0   0   1   0   1   1   1  32   7\n",
      "  183  26]\n",
      " [ 56   0   0   0   0   0   1   0   0   0   0   0   0   0   0  13  13   1\n",
      "   21 160]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_data,y_pred))\n",
    "print(confusion_matrix(y_test_data,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing our NAIVE BAYES CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionary from the training data\n",
    "def fit(x_train,y_train):\n",
    "    result={}\n",
    "    class_values = set(y_train) #distinct class values\n",
    "    for current_class in class_values:\n",
    "        result[current_class] = {}\n",
    "        result[\"total_docs\"]= x_train.shape[0] #total_docs: total num of documents\n",
    "        current_class_rows = (y_train == current_class) #returns true/false array\n",
    "        x_train_current = x_train[current_class_rows] #X_train_current is the array of rows with the specified class\n",
    "        y_train_current = y_train[current_class_rows] #Y_train_current is the y with the specified class\n",
    "        num_features = x_train.shape[1] #2000 words\n",
    "        total_count=0 \n",
    "        for j in range(num_features): #go through all the words\n",
    "            count = x_train_current[:,j].sum() #No of Wi in current class\n",
    "            result[current_class][j]= count\n",
    "            total_count= total_count+count\n",
    "        result[current_class][\"count_words_class\"]= total_count #No of words in currentClass\n",
    "        result[current_class][\"count_docs_class\"]= x_train_current.shape[0] #No of documents of the class\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computes log probability of the current class\n",
    "def probability(dictionary, x, current_class):\n",
    "    output = np.log(dictionary[current_class][\"count_docs_class\"]) - np.log(dictionary[\"total_docs\"]) #P(y=c1)\n",
    "    num_features = len(dictionary[current_class].keys()) - 2; #sice last 2 are (count_words_class & count_docs_class)\n",
    "    \n",
    "    #go through each feature\n",
    "    #compute PI( P(Wj= wj / y=ci))\n",
    "    for j in range(num_features):\n",
    "        xj = x[j] #freq of that word\n",
    "        if xj==0: #if word doesnt exist in input\n",
    "            continue\n",
    "        count_current_class_with_value_xj = dictionary[current_class][j] + 1 #add Laplace correction\n",
    "        count_current_class = dictionary[current_class][\"count_words_class\"] + num_features \n",
    "        current_xj_probability = np.log(count_current_class_with_value_xj) - np.log(count_current_class)\n",
    "        current_xj_probability= xj * current_xj_probability #log(m^n)= nlog(m)\n",
    "        output = output + current_xj_probability\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict class for a single row of input\n",
    "def predictSinglePoint(dictionary, x):\n",
    "    classes = dictionary.keys()\n",
    "    best_p = -1000\n",
    "    best_class = -1\n",
    "    first_run = True\n",
    "    for current_class in classes:\n",
    "        if (current_class == \"total_docs\"): #Since,total_docs is also a key\n",
    "            continue\n",
    "        #find prob for every class and choose the class with max Prob\n",
    "        p_current_class = probability(dictionary, x, current_class) \n",
    "        if (first_run or p_current_class > best_p):\n",
    "            best_p = p_current_class\n",
    "            best_class = current_class\n",
    "        first_run = False\n",
    "    return best_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dictionary, x_test):\n",
    "    y_pred = []\n",
    "    for x in x_test:\n",
    "        x_class = predictSinglePoint(dictionary, x) #predict y for a single row of input\n",
    "        y_pred.append(x_class)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use our Naive Bayes Classifier to predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the fit function returns the dictionary from the training data\n",
    "dictionary = fit(x_train_data,y_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict function returns the Y_pred, takes dictionary as input\n",
    "y_pred = predict(dictionary,x_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.8666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "print ('Accuracy Score :',accuracy_score(y_test_data, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.79      0.82      0.81       257\n",
      "           comp.graphics       0.86      0.76      0.81       248\n",
      " comp.os.ms-windows.misc       0.85      0.84      0.85       251\n",
      "comp.sys.ibm.pc.hardware       0.74      0.82      0.78       218\n",
      "   comp.sys.mac.hardware       0.83      0.90      0.86       255\n",
      "          comp.windows.x       0.89      0.76      0.82       232\n",
      "            misc.forsale       0.78      0.94      0.85       245\n",
      "               rec.autos       0.88      0.91      0.89       232\n",
      "         rec.motorcycles       0.91      0.96      0.93       254\n",
      "      rec.sport.baseball       0.94      0.92      0.93       266\n",
      "        rec.sport.hockey       0.94      0.93      0.93       241\n",
      "               sci.crypt       0.98      0.95      0.96       256\n",
      "         sci.electronics       0.85      0.91      0.88       264\n",
      "                 sci.med       0.96      0.89      0.92       230\n",
      "               sci.space       0.95      0.91      0.93       257\n",
      "  soc.religion.christian       0.94      1.00      0.97       258\n",
      "      talk.politics.guns       0.82      0.92      0.87       268\n",
      "   talk.politics.mideast       0.95      0.88      0.92       248\n",
      "      talk.politics.misc       0.80      0.72      0.76       255\n",
      "      talk.religion.misc       0.70      0.60      0.65       265\n",
      "\n",
      "                accuracy                           0.87      5000\n",
      "               macro avg       0.87      0.87      0.87      5000\n",
      "            weighted avg       0.87      0.87      0.87      5000\n",
      "\n",
      "[[212   0   0   0   0   0   1   1   2   0   0   0   0   1   1   2   0   1\n",
      "    0  36]\n",
      " [  0 188  12  20   7   6   7   2   1   0   0   1   2   0   2   0   0   0\n",
      "    0   0]\n",
      " [  0   4 211  15   1  14   4   0   0   0   0   0   1   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   4   2 179  27   1   2   0   0   0   0   0   3   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   3   2  12 229   0   5   0   0   0   0   0   4   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0  12  19   8   4 177   4   0   2   0   1   0   2   2   1   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   3   2   0 231   3   2   0   0   0   3   0   0   0   1   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   9 210   4   0   1   0   7   0   0   0   0   0\n",
      "    0   1]\n",
      " [  0   0   0   0   0   1   5   4 243   0   0   0   0   1   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   3   3   2 244  12   0   0   0   2   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   4   2   0  11 223   0   0   0   0   0   0   0\n",
      "    1   0]\n",
      " [  0   2   1   0   0   1   1   0   0   0   0 243   6   1   0   0   1   0\n",
      "    0   0]\n",
      " [  0   0   0   4   6   0   3   6   1   0   0   0 239   2   2   0   0   1\n",
      "    0   0]\n",
      " [  0   2   0   1   1   0   7   0   5   0   0   0   6 205   1   0   0   1\n",
      "    0   1]\n",
      " [  1   4   0   0   0   0   2   3   0   4   0   0   7   1 233   0   0   0\n",
      "    2   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 258   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   1   2   0   0   3   0   0   0   0 246   0\n",
      "   11   5]\n",
      " [  0   0   0   0   0   0   5   3   2   0   0   0   0   0   0   0   7 219\n",
      "   11   1]\n",
      " [  0   0   0   0   0   0   3   0   0   0   0   1   0   1   1   1  32   7\n",
      "  183  26]\n",
      " [ 56   0   0   0   0   0   1   0   0   0   0   0   0   0   0  13  13   1\n",
      "   21 160]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_data,y_pred))\n",
    "print(confusion_matrix(y_test_data,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Sklearn Multinomial Naive Bayes and Our Naive Bayes implementation gave exactly the same accuracy and confusion Matrix. The accuracy largely depends on the selection of words(preprocessing of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
